{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atlas Reader\n",
    "\n",
    "[Atlas Reader](https://github.com/miykael/atlasreader) is a Python interface for generating coordinate tables and region labels from statistical MRI images.\n",
    "\n",
    "## Installing `atlasreader`\n",
    "\n",
    "Provided you have `pip` at your disposal, installing `atlasreader` is as simple as this:\n",
    "\n",
    "```pip install -U atlasreader```\n",
    "\n",
    "\n",
    "## Using `atlasreader`\n",
    "\n",
    "`atlasreader` can either be run through the command line interface, or directly within Python. To showcase both of those examples, let's first import relevant plotting functions for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import plotting\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's grab an example stat map. We'll use `nilearn` to grab a motor task stat map from [neurovault](https://neurovault.org/). Note that you'll need the most up to date version of `nilearn` in order to run `fetch_neurovault_motor_task()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.datasets import fetch_neurovault_motor_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a stat map from neurovault using nilearn\n",
    "motor_images = fetch_neurovault_motor_task()\n",
    "stat_img = motor_images.images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what does our example data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_glass_brain(stat_img, black_bg=True, threshold=5, vmax=10,\n",
    "                          colorbar=True, plot_abs=False, display_mode='lyrz',\n",
    "                          title='Finger tapping task')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we can see that there are a few particular clusters, if we threshold the data at a value of 5.\n",
    "\n",
    "`atlasreader` gives you now the opportunity to better understand where the peaks of those clusters are, over which regions the clusters extend, and much more. So, how is it done?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling `atlasreader` from Python\n",
    "\n",
    "If you want run `atlasreader` directly in Python, just import the `create_output()` function, and you're good to go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atlasreader.atlasreader import create_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, so now we can run `atlasreader` and provide our stat map and an out directory `'.'`. Let's threshold our _t_ values to 5, set the `extent` to 10 in order to get robust clusters of at least 10 or more voxels and ask to only extract information for the the [AAL](http://neuro.imm.dtu.dk/wiki/Automated_Anatomical_Labeling) atlas only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_output(stat_img,\n",
    "              atlas='aal',\n",
    "              voxel_thresh=5,\n",
    "              cluster_extent=0,\n",
    "              prob_thresh=0,\n",
    "              outdir='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an output we get four different kind of files.\n",
    "\n",
    "*First*, an overview glass brain plot, with the name of `stat_img` but with the file ending `.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('image_10426.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Second*, a statistical map plot for each cluster found in the data, centered around the peak of this cluster. Those files all end with `_cluster01.png`, `_cluster02.png`, ...:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('image_10426_cluster01.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('image_10426_cluster02.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Third*, a csv file ending with `_peaks.csv`, containing the location of each cluster's peak, it's signal value at this location and the atlas correspondence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('image_10426_peaks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Forth*, a csv file ending with `_clusters.csv`, containing the location of each cluster's peak, it's mean value, its cluster extend, as well as the membership of each cluster, given a particular atlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('image_10426_clusters.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, in the csv table shown above, we know that 51.68% of the first cluster is in the righ postcentral and 28.75% is in the right precentral area, according to the AAL atlas.\n",
    "\n",
    "### Adapting cluster parameters\n",
    "\n",
    "As you can see, there are some clusters with a cluster extend of less than 5000 mm³ (i.e. with a voxel resolution of 3mm x 3mm x 3mm this corresponds to about 185 voxels.\n",
    "\n",
    "So, let's say we want to ignore those clusters with less than 185 voxles / 5000 mm³ and get the atlas information for FreeSurfer's *Desikan_Killiany* and FSL's *Harvard-Oxford* atlas. To do this, we can adapt the parameters as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_output(stat_img,\n",
    "              atlas=['Desikan_Killiany', 'Harvard_Oxford'],\n",
    "              voxel_thresh=5,\n",
    "              cluster_extent=185,\n",
    "              prob_thresh=0,\n",
    "              outdir='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the glass brain again, we see that only the biggest clusters have survived the restrictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('image_10426.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And looking at the two CSV tables, we can see that we now have peak and cluster information for two atlases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('image_10426_peaks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('image_10426_clusters.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting the plots\n",
    "\n",
    "In addition to changing our selection criteria for the plots, we can also change the style of the plots. We might want to tweak the default plotting style to have a white background, or adjust the colormap used to convey the clusters. This customization is done separately for the glass brain plot and the cluster plots using the `_kws` arguments in `create_output`. These parameters are dictionaries that contain keyword arguments for the `nilearn` functions used to create these plots (see the keyword arguments for [plot_glass_brain](http://nilearn.github.io/modules/generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain) and [plot_stat_map](http://nilearn.github.io/modules/generated/nilearn.plotting.plot_stat_map.html#nilearn.plotting.plot_stat_map)).\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_output(stat_img,\n",
    "              atlas=['Desikan_Killiany', 'Harvard_Oxford'],\n",
    "              voxel_thresh=5,\n",
    "              cluster_extent=185,\n",
    "              prob_thresh=0,\n",
    "              outdir='.', \n",
    "              glass_plot_kws={'black_bg': False, 'vmax': 10},\n",
    "              stat_plot_kws={'black_bg': False, 'title': None})\n",
    "\n",
    "Image('image_10426.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title is now removed for all cluster plots\n",
    "Image('image_10426_cluster01.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have flexibility with how we want to select our clusters and how we wish to plot them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `atlasreader` from the Command Line\n",
    "\n",
    "This is all super exciting! But as promised before, `atlasreader` can also be run directly from the command line. Assuming you installed it via `pip`.\n",
    "\n",
    "Let's begin with running the `help` argument so we can look at the input parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "atlasreader -h "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! As you can see, we have the same input parameters available as if we would run `atlasreader` within Python.\n",
    "\n",
    "So let's try something new out. Let's set the *probability threshold* to 40%  to remove small probabilities and the *atlas* to `all` to extract information for all atlases. The rest we can keep as in the example before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$stat_img\"\n",
    "atlasreader -a all -t 5 -c 185 -p 40 -o . $1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The glassbrain will look the same, but what about the csv tables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('image_10426_peaks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we now get atlas information for all the atlases included in `atlasreader`. Currently those are AAL, FreeSurfer's Desikan-Killiany & Destrieux, FSL's Harvard-Oxford, Juelich, Neuromorphometrics and Talairach atlas. This is due to the fact that we set the parameter `atlas` to `'all`.\n",
    "\n",
    "But what about the `probability threshold` parameter at 40%? This means that only atlas memberships of higher than 40% are shown in the tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('image_10426_clusters.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That this is the case, becomes more eminent, if we run the same command again, but this time with the `probability threshold` parameters set to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$stat_img\"\n",
    "atlasreader -a all -t 5 -c 185 -p 0 -o . $1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('image_10426_clusters.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
